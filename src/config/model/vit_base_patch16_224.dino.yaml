name: vit_base_patch16_224.dino
source: timm  # Options: timm, openclip
pretrained: true
freeze_backbone: false  # Whether to freeze the backbone during training
freeze_classifier: false  # Whether to freeze the classifier during training
feature_dim: 768  # Feature dimension for ViT base
classifier:
  type: linear  # Options: linear, mlp
  hidden_dim: 512  # Only used if type is mlp
  dropout: 0.1
  normalize: false
  temperature: 1.0
sae:
  use_sae: false
  checkpoint_path: "/path/to/your/sae_checkpoint.pt"
  layer: -2  # Apply SAE to the second-to-last transformer layer
  token_type: all  # Apply SAE to 'patch', 'cls', or 'all'
